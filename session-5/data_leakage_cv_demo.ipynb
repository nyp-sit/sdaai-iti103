{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "data_leakage_cv.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/session-5/data_leakage_cv_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNzfxPCSE4qg"
      },
      "source": [
        "# Data Leakage in Cross Validation\n",
        "\n",
        "The impact of data leakage in the cross-validation varies, depending on what kind of pre-processing. Estimate the scaling factor, e.g. as described in lecture, usually does not have a large impact, but for others such as feature extraction or feature selection, data leakage can lead to vast differences in the model 'true' predictive power. \n",
        "\n",
        "The purpose of this exercise is to illustrate the impact of data leakage on model's accuracy.  It is based on an excellent example from Elements of Statistical Learning (by Trevor Hastie, et al.), from the section *The Wrong and Eight Way to Do Cross-validation*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-KEICVKE4qh"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FzmeAJSE4qh"
      },
      "source": [
        "Letâ€™s consider a synthetic classification task with 100 samples and\n",
        "1,000 features that are sampled independently from a Gaussian distribution. We also\n",
        "randomly sample the response from \\[0,1\\] for binary labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_DB3iWME4qi"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "rnd = np.random.RandomState(seed=0)\n",
        "\n",
        "# generate 1000 samples with 10000 features from Normal distribution\n",
        "X = rnd.normal(size=(1000, 10000))\n",
        "\n",
        "# generate 1000 binary labels with equal probability\n",
        "y =  np.random.choice([0, 1], size=(1000,), p=[0.5, 0.5])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQg7w_yQE4qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef557f2-3501-4e84-ae36-5a8a3c447d00"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 10000), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK8H6dG4E4qj"
      },
      "source": [
        "Given that X and y are sampled independently from the distribution, there should not be any relation between X and y, and the expected test error rate should be around 50%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgslumFQE4qk"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWQWwb04E4qk"
      },
      "source": [
        "First, select the most informative of the features using SelectPercentile feature selection, and then we evaluate a LogisticRegressor using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK39yJmZE4qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ee67af-a384-4c6c-f9bc-100bac57f872"
      },
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X_train, y_train)\n",
        "X_selected = select.transform(X_train)\n",
        "\n",
        "print(\"X_selected.shape: {}\".format(X_selected.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_selected.shape: (800, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM-nQat4E4ql"
      },
      "source": [
        "## Cross Validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpDQgjmHE4ql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68902cf-a031-405f-c411-3e7e85dc4b05"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "scores = cross_val_score(LogisticRegression(), X_selected, y_train, cv=5)\n",
        "mean_accuracy = np.mean(scores)\n",
        "print(\"Cross-validation accuracy: {:.2f}\".format(mean_accuracy))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation accuracy: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxAczKq2E4qm"
      },
      "source": [
        "Looks like a decent validation accuracy, let's try on our test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMrKGxq1E4qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed038de7-b6ed-4356-bdc7-e158ca5751d2"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkmxJL_4E4qm"
      },
      "source": [
        "The result is no better than random guess (50%)!! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyhwQV_PE4qm"
      },
      "source": [
        "Now let's do a 'proper' cross validation on our model: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWO7wlRpE4qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59c3098-9de6-4055-d753-75d1dd451ef3"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "pipeline = Pipeline([(\"select\", SelectPercentile(score_func=f_regression, percentile=5)),\n",
        "                     (\"lr\", LogisticRegression())])\n",
        "scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
        "mean_accuracy = np.mean(scores)\n",
        "print(\"Cross-validation accuracy (pipeline): {:.2f}\".format(mean_accuracy))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation accuracy (pipeline): 0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SC079AeE4qn"
      },
      "source": [
        "this time round, the cross-validation accuracy gives a true-er picture of the model performance (i.e. 50%). "
      ]
    }
  ]
}