{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plot_learning_curve.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/session-5/plot_learning_curve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iMc4C81wkrV"
      },
      "source": [
        "# Plotting Learning Curves\n",
        "\n",
        "Welcome to the hands-on lab. This is part of a series of exercises to help you to acquire skills in different techniques to fine-tune your machine learning model. \n",
        "\n",
        "In this lab, you will learn how to:\n",
        "- diagnose overfitting/underfitting problems in machine learning  \n",
        "- plot learning curves for both classification and regression types of problems\n",
        "\n",
        "*Acknowledgement: This exercise is adapted from https://www.dataquest.io/blog/learning-curves-machine-learning/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npRJnOmjwkrY"
      },
      "source": [
        "## 1. Import Required Packages ##\n",
        "\n",
        "Let's first import all the packages that you will need during this exercise.\n",
        "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
        "- [sklearn](http://scikit-learn.org/stable/) provides simple and efficient tools for data mining and data analysis. \n",
        "- [matplotlib](http://matplotlib.org) is a library for plotting graphs in Python.\n",
        "- [pandas](https://pandas.pydata.org) is a library for data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQxquDNVwkra"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu_xkvFvwkrl"
      },
      "source": [
        "## 2. Learning Curve for Regression Problem ##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Data\n",
        "\n",
        "First, let's get the dataset you will work on. The description of the data can be found [here](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)"
      ],
      "metadata": {
        "id": "9-zJH8rboPtr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncSjozEGwkro"
      },
      "source": [
        "# if you are using jupyter notebook and wish to load the data locally\n",
        "# electricity = pd.read_excel('data/combined_pp.xlsx)\n",
        "# if you wish to load data from an url\n",
        "electricity = pd.read_excel('https://github.com/nyp-sit/sdaai-iti103/raw/master/session-5/data/combined_pp.xlsx')\n",
        "electricity.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the data types and also check if there is any missing values."
      ],
      "metadata": {
        "id": "rO2W8KD3nxIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electricity.info()"
      ],
      "metadata": {
        "id": "dQqT8WOznjl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_lA5FINwkrw"
      },
      "source": [
        "Let's separate the features from the target and instantiate a LinearRegressor as the estimator to be used later. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fPvU9Qjwkry"
      },
      "source": [
        "# We separate the features and target from the data set\n",
        "features = ['AT','V','AP','RH']\n",
        "target = 'PE'\n",
        "\n",
        "X = electricity[features]\n",
        "y = electricity[target]\n",
        "\n",
        "# Instantiate a LinearRegressor\n",
        "estimator = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGEcloRVwkr9"
      },
      "source": [
        "### Plot the learning curve \n",
        "\n",
        "`learning_curve()` in scikit-learn can be used to  generate the data needed to plot a learning curve, i.e. the training and validation scores. The function returns a tuple containing three elements: ``train_sizes``, and ``train_scores`` and ``validation_scores``. The function accepts the following parameters:\n",
        "- estimator — indicates the learning algorithm we use to estimate the true model\n",
        "- X — the features\n",
        "- y — the target labels\n",
        "- train_sizes — the numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set (that is determined by the selected validation method), i.e. it has to be within (0, 1]. (Note: the notation (0,1] means inclusive of 0 but exclusive of 1). Otherwise it is interpreted as absolute sizes of the training sets. \n",
        "- cv — determines the cross-validation splitting strategy.\n",
        "- scoring — controls the metrics used to evaluate estimator. Possible pre-defined metrics can be found [here](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
        "- shuffle - whether to shuffle training data before taking prefixes of it based on ``train_sizes``.\n",
        "\n",
        "You can refer to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html) for more detail of the function. \n",
        "\n",
        "There are a total of 9568 rows of data. If we are using 5-fold cross validation, only $4/5$ or 80% of the data are availabel for training which is around 7654 samples. We will plot the training curve for training sizes of 1, 100, 500, 2000, 5000, 7654. \n",
        "For the scoring metric, we will choose `'neg_mean_squared_error'`. There is no `'mean_squared_error'` because this metric supposed to measure how good the model is, and not how much error the model made. \n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "    \n",
        "train_sizes = [1,100,500,2000,5000,7654]\n",
        "    \n",
        "train_sizes, train_scores, validation_scores = learning_curve(\n",
        "                    estimator, X, y, train_sizes = train_sizes, cv=5,\n",
        "                    scoring = 'neg_mean_squared_error',\n",
        "                    shuffle=False, random_state=0)\n",
        "    \n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd2Tj5lUwksA"
      },
      "source": [
        "# declare the list of different training sizes\n",
        "train_sizes = [1, 100, 500, 2000, 5000, 7654]\n",
        "\n",
        "# call the learning_curve() to return train_scores/validation scores for different train sizes\n",
        "train_sizes, train_scores, validation_scores = learning_curve(\n",
        "                    estimator, X, y, train_sizes = train_sizes, cv=5,\n",
        "                    scoring = 'neg_mean_squared_error',\n",
        "                    shuffle=False, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llc3GDOrwksK"
      },
      "source": [
        "Let us print out the values of train_scores and validation_scores(neg_mean_squared_error). Each row corresponds to a test size and each columns corresponds to a split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIvmnLM6wksM"
      },
      "source": [
        "# print the train and validation scores\n",
        "print('Train scores:\\n\\n', train_scores)\n",
        "print('\\n','-'*70)\n",
        "print('\\nValidation scores:\\n\\n', validation_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdLtdkg5wksU"
      },
      "source": [
        "You might have noticed that some error scores on the training sets are the same. For the row corresponding to training set size of 1, this is expected, but what about other rows? With the exception of the last row, we have a lot of identical values. For instance, take the second row where we have identical values from the second split onward. Why is that so? \n",
        "\n",
        "This is caused by not randomizing the training data for each split. Let’s walk through a single example with the aid of the diagram below. When the training size is 100 the first 100 samples in the training set are selected.\n",
        "\n",
        "For the first split, these 100 samples will be taken from the second chunk. From the second split onward, these 100 samples will be taken from the first chunk. Because we don’t randomize the training set, the 100 samples used for training are the same for the second split onward. This explains the identical values from the second split onward for the 100 training instances case. The same reasoning applies to the case of training size of 500, and so on. \n",
        "\n",
        "<div>\n",
        "<img src=\"https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/resources/iti103/learning_curve_splits.png\" alt=\"k-fold\" width=\"600\" align='center'/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ_eF5Y7wksW"
      },
      "source": [
        "\n",
        "You can fix this problem by setting ``shuffle`` to **``True``** in the call to ``learning_curve()``.  Note that the train_scores are no more have identical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh-G6Ta-wksZ"
      },
      "source": [
        "train_sizes, train_scores, validation_scores = learning_curve(\n",
        "                    estimator, X, y, train_sizes = train_sizes, cv=5,\n",
        "                    scoring = 'neg_mean_squared_error',\n",
        "                    shuffle=True, random_state=0)\n",
        "\n",
        "# print the train and validation scores\n",
        "print('Train scores:\\n\\n', train_scores)\n",
        "print('\\n','-'*70)\n",
        "print('\\nValidation scores:\\n\\n', validation_scores)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxvZy6cawksi"
      },
      "source": [
        "To plot the learning curves, we need only a single error score per training set size, not 5. So we will take the mean values of the 5 error scores (for the 5 splits), which corresponds to axis 1.\n",
        "The scores returned are negative mean squared error,  which are negative values. So we will need to negate the values to the MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZhDMISDwkso"
      },
      "source": [
        "train_errors_mean = -train_scores.mean(axis=1)\n",
        "validation_errors_mean = -validation_scores.mean(axis=1)  \n",
        "\n",
        "# print out the errors # \n",
        "print('Mean training errors:\\n', pd.Series(train_errors_mean, index=train_sizes))\n",
        "print('\\n', '-'*50)\n",
        "print('Mean validation errors:\\n', pd.Series(validation_errors_mean, index=train_sizes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Hoaigowks4"
      },
      "source": [
        "Let's define a function ``plot_curve()`` that will plot the train_errors, validation_errors against train_size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFqHrH-lwks6"
      },
      "source": [
        "def plot_curve(title, ylabel, train_sizes, train_scores, validation_scores, ylim=None):\n",
        "    plt.style.use('seaborn')\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)    \n",
        "    plt.xlabel(\"Training size\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.plot(train_sizes, train_scores, 'o-', color=\"r\",\n",
        "             label=\"Training\")\n",
        "    plt.plot(train_sizes, validation_scores, 'o-', color=\"g\",\n",
        "             label=\"Validation\")\n",
        "    plt.legend(loc=\"best\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3h1ttWAwktG"
      },
      "source": [
        "\n",
        "Plot the learning curve using the above function. We also need to limit the range of y-axis to (0,40) as the MSE for training size of 1 is very large compared to the rest, and we want to see the details of MSEs for other training sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnQxQMGewktI"
      },
      "source": [
        "plot_curve('Linear Regression', 'MSE', train_sizes, \n",
        "             train_errors_mean, validation_errors_mean, ylim=(0,40))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHzP0wJ9wktP"
      },
      "source": [
        "The validation MSE seems to stagnate at a value of approximately 20. Is this good enough? \n",
        "\n",
        "We’d benefit from some domain knowledge.\n",
        "Technically, that value of 20 has MW (megawatts squared) as units (the units get squared as well when we compute the MSE). The values in our target column are in MW (according to the documentation). Taking the square root of 20 MW results in approximately 4.5 MW. Each target value represents net hourly electrical energy output. So for each hour our model is off by 4.5 MW on average. According to this [Quora](https://www.quora.com/How-can-I-get-an-intuitive-understanding-of-what-a-Kw-Mw-Gw-of-electricity-equates-to-in-real-life-terms) answer, 4.5 MW is equivalent to the heat power produced by 4500 handheld hair dryers. And this would add up if we tried to predict the total energy output for one day or a longer period. We can conclude that the an MSE of 20 MW is quite large. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhyttoD0wktR"
      },
      "source": [
        "***Exercise***:\n",
        "\n",
        "Examine the learning curve you plot, answer the following questions (don't look at the answer first).\n",
        "\n",
        "1. Is this a high-bias problem or a low-bias problem?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>High Bias</p></details>\n",
        "\n",
        "2. Is it high variance or low variance?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>Low Variance</p></details>\n",
        "\n",
        "3. Will adding more training data help to improve the performance of the model?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>No</p></details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBr189UmwktT"
      },
      "source": [
        "We can try to reduce the bias with the following methods:\n",
        "- use a more complex learning algorithm\n",
        "- add more features (not samples) or try generate polynomial features from existing features\n",
        "- reduce regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJfS7RV7wktV"
      },
      "source": [
        "Let's try using RandomForestRegressor instead. You don't need to know the details of RandomForestRegressor, and we are just using it to see how it impacts the bias/variance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFAtfKvGwktY"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "estimator=RandomForestRegressor(n_estimators=30)\n",
        "train_sizes, train_scores, validation_scores = learning_curve(\n",
        "                    estimator, X, y, train_sizes = train_sizes, cv=5,\n",
        "                    scoring = 'neg_mean_squared_error',\n",
        "                    shuffle=True, random_state=0)\n",
        "\n",
        "train_errors_mean = -train_scores.mean(axis = 1)\n",
        "validation_errors_mean = -validation_scores.mean(axis = 1)\n",
        "\n",
        "plot_curve('RandomForest Regressor', 'MSE', train_sizes, train_errors_mean, validation_errors_mean, ylim=(0,40))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6izl3gzwktf"
      },
      "source": [
        "***Exercise:***\n",
        "\n",
        "1. Does the new learning curve show a low or high bias?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>Low Bias</p></details>\n",
        "\n",
        "2. Does the new learning curve show a low or high variance?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>High Variance</p></details>\n",
        "\n",
        "3. Will adding more training data help to improve the performance of the model?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>Yes, this may help</p></details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnmzZbn1wkth"
      },
      "source": [
        "## 3. Learning Curve for Classification Problem ##\n",
        "\n",
        "First, let's get the dataset you will work on. The following code will load a \"[digits](https://scikit-learn.org/stable/datasets/index.html#digits-dataset)\" dataset into variables `X` and `y`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPUBvGfdwktj"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4bcl0scwktw"
      },
      "source": [
        "You have:\n",
        "- a numpy-array X that contains your features (the pixel values)\n",
        "- a numpy-array y that contains your labels (digits 0 to 9).\n",
        "\n",
        "Lets first get a better sense of what our data is like. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU3KHutEwkt3"
      },
      "source": [
        "shape_X = X.shape\n",
        "shape_y = y.shape\n",
        "print ('The shape of X is: ' + str(shape_X))\n",
        "print ('The shape of y is: ' + str(shape_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0yV6MmQwkuG"
      },
      "source": [
        "Let us visualize some digit in the data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6SguCQYwkuJ"
      },
      "source": [
        "some_digit = X[3]\n",
        "some_label = y[3]\n",
        "some_digit_image = some_digit.reshape(8, 8)\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(some_digit_image, cmap = plt.cm.binary, interpolation=\"nearest\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print('Label = {}'.format(some_label))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdWEUa96wkup"
      },
      "source": [
        "**learning_curve()** expects a param called **train_sizes**, which are numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set (that is determined by the selected validation method), i.e. it has to be within (0, 1]. Otherwise it is interpreted as absolute sizes of the training sets. Note that for classification the number of samples usually have to be big enough to contain at least one sample from each class.\n",
        "\n",
        "***Exercise:***\n",
        "\n",
        "Divide the number training samples into 5 equal sizes, starting from 0.1 (i.e. 10% of the training samples). \n",
        "\n",
        "**Hint:**\n",
        "Use [numpy.linspace()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)\n",
        "\n",
        "\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "train_sizes = np.linspace(0.1, 1.0, 5)\n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuyW8oSEwkuu"
      },
      "source": [
        "### START CODE HERE ### \n",
        "\n",
        "train_sizes = ??\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(train_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEjzuHNswkvA"
      },
      "source": [
        "***Exercise:***\n",
        "\n",
        "Create a LogisticRegression estimator with solver='liblinear' and multi-class='auto' and call the ``learning_curve()`` function to get the train and validation scores. Use a 5-fold cross-validation. You need to choose scoring metrics appropriate for classification problem (e.g. 'accuracy'). Specify random_state=0 for repeatability.\n",
        "\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "estimator = LogisticRegression(solver='liblinear', multi_class='auto')\n",
        "train_sizes, train_scores, validation_scores = learning_curve(\n",
        "        estimator, X, y, cv=5, scoring='accuracy', train_sizes=train_sizes, shuffle=True, random_state=0)\n",
        "```\n",
        "    \n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1_cm6-lwkvE"
      },
      "source": [
        "### START CODE HERE ### \n",
        "\n",
        "estimator = ??\n",
        "train_sizes, train_scores, validation_scores = ??\n",
        "\n",
        "### END CODE HERE ### \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdeyyZB4wkvL"
      },
      "source": [
        "***Exercise:***\n",
        "\n",
        "What do you think are the shapes of the train_scores and test_scores?\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<p>\n",
        "Since we specify 5 training sizes, for each training, we specify a 5-fold cross-validations, we should have 5 x 5 train_scores and test_scores.\n",
        "</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt_UPMTCwkvM"
      },
      "source": [
        "## Uncomment the following to check your answers\n",
        "\n",
        "# print(train_scores.shape)\n",
        "# print(validation_scores.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJjVul36wkvX"
      },
      "source": [
        "***Exercise:*** \n",
        "\n",
        "To plot the learning curves, we need only a single score per training set size, not 5. To do this we need to take the mean value of 5 scores of each training/validation round. As the scores is the accuracy scores, you will need to convert them to error rate. \n",
        "\n",
        "***Hint:***  Fraction of error = 1.0 - (fraction of correct)\n",
        "\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "train_errors_mean = 1. - np.mean(train_scores, axis=1)\n",
        "validation_errors_mean = 1. - np.mean(validation_scores, axis=1)\n",
        "    \n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul4NCkzswkvZ"
      },
      "source": [
        "### START CODE HERE ### (~ 2 lines of code)\n",
        "\n",
        "\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa-JltaUwkvf"
      },
      "source": [
        "### Plot the learning curve ###\n",
        "Ok, now we can start plotting the curve. You should expect to see a learning curve similar to the following:\n",
        "\n",
        "<img src=\"https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/resources/iti103/classification_lc.png\" alt=\"classification learning curve\" width=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agNlVEUqwkvh"
      },
      "source": [
        "***Exercise:***\n",
        "\n",
        "Plot the learning curve for logistic regression. \n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "plot_curve('Logistic Regression', 'Error', train_sizes, train_errors_mean, validation_errors_mean)\n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsrbIDbywkvj"
      },
      "source": [
        "### START CODE HERE ### \n",
        "\n",
        "\n",
        "### END CODE HERE ### \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6v5hmqWwkvv"
      },
      "source": [
        "***Exercise:***\n",
        "\n",
        "Is this a high-bias or high variance problem?\n",
        "<details><summary>Click here for answer</summary><p>High variance</p></details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao4UoETywkvx"
      },
      "source": [
        "Let us try a more complex non-linear algorithm such as Support Vector Machine (SVM). \n",
        "You don't need to know the details of SVM, and we are just using it to see how it impacts the bias/variance. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_6-R7aQwkv2"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "estimator=SVC()\n",
        "train_sizes, train_scores, validation_scores = learning_curve(estimator, X, y, \n",
        "                                                              cv=5, scoring='accuracy', \n",
        "                                                              train_sizes=train_sizes, \n",
        "                                                              shuffle=True, random_state=0)\n",
        "train_errors_mean = 1. - np.mean(train_scores, axis=1)\n",
        "validation_errors_mean = 1. - np.mean(validation_scores, axis=1)\n",
        "plot_curve('SVM', 'Error', train_sizes, train_errors_mean, validation_errors_mean)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ZF7SmGwkv9"
      },
      "source": [
        "***Exercise:***\n",
        "\n",
        "How does the use of SVM affect bias and variance of the model?\n",
        "\n",
        "<details><summary>Click here for answer</summary><p>In this case, using a more complex, non-linear algoritm such as SVM improves variance of the model, while the bias is kept low too.</p></details>"
      ]
    }
  ]
}