{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Ex2_GradientDescent.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/session-6/Ex2_GradientDescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuagyp6xQFGO"
      },
      "source": [
        "# Gradient Descent\n",
        "\n",
        "Welcome to the hands-on lab. This is part of the series of exercises to help you acquire skills in different techniques to fine-tune your model.\n",
        "\n",
        "In this lab, you will learn:\n",
        "- how to use SGD Regressor to train your model \n",
        "- how learning rate and features scaling impact the performance of gradient descent-based algorithms\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTBk1cViQFGR"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWHxkLSQFGR"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', module='sklearn')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjrKSbZiQFGS"
      },
      "source": [
        "Here we will load the boston housing prices. The dataset is not scaled and we train models using different regression: Linear regression, Ridge, Lasso and ElasticNet and compare their RMSE.  We then compare the RMSEs with a SGDRegressor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSoqTFvnQFGS"
      },
      "source": [
        "def load_boston_data():\n",
        "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "    target = raw_df.values[1::2, 2]\n",
        "    \n",
        "    return data, target\n",
        "\n",
        "X, y = load_boston_data()\n",
        "\n",
        "# Split the data into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPM5ZUT8QFGS"
      },
      "source": [
        "We define a function to calculate RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js9kILQWQFGT"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def rmse(ytrue, ypredicted):\n",
        "    return np.sqrt(mean_squared_error(ytrue, ypredicted))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNXLJwuJQFGT"
      },
      "source": [
        "We train a plain vanilla **Linear Regression** and calcuate the RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bap8yngiQFGT"
      },
      "source": [
        "linearRegression = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "linearRegression_rmse = rmse(y_test, linearRegression.predict(X_test))\n",
        "\n",
        "print(linearRegression_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uywFa62GQFGT"
      },
      "source": [
        "We then train a model using **Ridge Regression**, and find the best alpha and the best RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeeYV4TrQFGU"
      },
      "source": [
        "alphas = [0.005, 0.05, 0.1, 0.3, 1, 3, 5]\n",
        "\n",
        "ridgeCV = RidgeCV(alphas=alphas, \n",
        "                  cv=5).fit(X_train, y_train)\n",
        "\n",
        "ridgeCV_rmse = rmse(y_test, ridgeCV.predict(X_test))\n",
        "\n",
        "print(ridgeCV.alpha_, ridgeCV_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ywHUA1QFGU"
      },
      "source": [
        "We then train a model using **Lasso Regression**, and find the best alpha and the best RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhSh2rRLQFGU"
      },
      "source": [
        "lasso_alphas = np.array([1e-5, 5e-5, 0.0001, 0.0005])\n",
        "\n",
        "lassoCV = LassoCV(alphas=lasso_alphas,\n",
        "                  max_iter=10000,\n",
        "                  cv=5).fit(X_train, y_train)\n",
        "\n",
        "lassoCV_rmse = rmse(y_test, lassoCV.predict(X_test))\n",
        "\n",
        "print(lassoCV.alpha_, lassoCV_rmse)  # Lasso is slower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeAKvGtQFGU"
      },
      "source": [
        "We then train a model using **ElasticNet Regression**, and find the best alpha, L1-ratio and the best RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_RmurwhQFGV"
      },
      "source": [
        "l1_ratios = np.linspace(0.1, 0.9, 9)\n",
        "\n",
        "elasticNetCV = ElasticNetCV(alphas=lasso_alphas, \n",
        "                            l1_ratio=l1_ratios,\n",
        "                            max_iter=10000, cv=5).fit(X_train, y_train)\n",
        "elasticNetCV_rmse = rmse(y_test, elasticNetCV.predict(X_test))\n",
        "\n",
        "print(elasticNetCV.alpha_, elasticNetCV.l1_ratio_, elasticNetCV_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCn1KcQ-QFGV"
      },
      "source": [
        "Now we will put all the best RMSEs of various models in a dataframe for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut4Cnf-sQFGV"
      },
      "source": [
        "rmse_vals = [linearRegression_rmse, ridgeCV_rmse, lassoCV_rmse, elasticNetCV_rmse]\n",
        "\n",
        "labels = ['Linear', 'Ridge', 'Lasso', 'ElasticNet']\n",
        "\n",
        "rmse_df = pd.Series(rmse_vals, index=labels).to_frame()\n",
        "rmse_df.rename(columns={0: 'RMSE'}, inplace=1)\n",
        "rmse_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj4vS__rQFGV"
      },
      "source": [
        "Now let's try to use the [**SGDRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html), and using same best hyper-parameters for ridge, lasso and elasticNet but uses the default starting learning rate (eta0) of 0.01 and the learning rate adjustment strategy of 'invscaling' i.e. eta = eta0 / pow(t, power_t)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXHhhTFaQFGV"
      },
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "\n",
        "model_parameters_dict = {\n",
        "    'Linear': {'penalty': None},\n",
        "    'Lasso': {'penalty': 'l1',\n",
        "           'alpha': lassoCV.alpha_},\n",
        "    'Ridge': {'penalty': 'l2',\n",
        "           'alpha': ridgeCV.alpha_},\n",
        "    'ElasticNet': {'penalty': 'elasticnet', \n",
        "                   'alpha': elasticNetCV.alpha_ ,\n",
        "                   'l1_ratio': elasticNetCV.l1_ratio_}\n",
        "}\n",
        "\n",
        "new_rmses = {}\n",
        "for modellabel, parameters in model_parameters_dict.items():\n",
        "    # following notation passes the dict items as arguments\n",
        "    SGD = SGDRegressor(**parameters)\n",
        "    SGD.fit(X_train, y_train)\n",
        "    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test))\n",
        "\n",
        "    \n",
        "rmse_df['RMSE-SGD'] = pd.Series(new_rmses).to_frame()\n",
        "rmse_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chiRgx6xQFGW"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "What do you observe about the RMSE? What do you think is the reason for the observed RMSE? \n",
        "\n",
        "_Type your answer here_\n",
        "    \n",
        "<details><summary>Click here for answer</summary>\n",
        "    \n",
        "Notice how high the error values are! The algorithm is diverging. This can be due to scaling and/or learning rate being too high. Let's adjust the learning rate and see what happens.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3MkYXxZQFGW"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Now let's try using a smaller learning rate of 1e-7 (i.e. 0.0000001) and apply the same version of SGD and compare the new RMSE of SGD with the new learning rate. \n",
        "\n",
        "Complete the codes in the following code cell.\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "    \n",
        "```python\n",
        "\n",
        "for modellabel, parameters in model_parameters_dict.items():\n",
        "    # following notation passes the dict items as arguments\n",
        "    SGD = SGDRegressor(eta0=1e-7, **parameters)\n",
        "    SGD.fit(X_train, y_train)\n",
        "    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0hV4roEQFGX"
      },
      "source": [
        "new_rmses = {}\n",
        "\n",
        "## START YOUR CODE HERE \n",
        "\n",
        "\n",
        "## END YOUR CODE HERE\n",
        "\n",
        "rmse_df['RMSE-SGD-learningrate'] = pd.Series(new_rmses)\n",
        "rmse_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYl1jCmAQFGX"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Now let's scale our training data and try again.\n",
        "\n",
        "* Fit a `MinMaxScaler` to `X_train` create a variable `X_train_scaled`.\n",
        "* Using the scaler, transform `X_test` and create a variable `X_test_scaled`. \n",
        "* Apply the same versions of SGD to them and compare the results. Don't pass in a eta0 this time.\n",
        "\n",
        "Complete the code in the following code cell.\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "    \n",
        "```python\n",
        "    \n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "for modellabel, parameters in model_parameters_dict.items():\n",
        "    # following notation passes the dict items as arguments\n",
        "    SGD = SGDRegressor(**parameters)\n",
        "    SGD.fit(X_train_scaled, y_train)\n",
        "    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test_scaled))\n",
        "\n",
        "rmse_df['RMSE-SGD-scaled'] = pd.Series(new_rmses)\n",
        "rmse_df\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUYMC8wHQFGX"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "new_rmses = {}\n",
        "\n",
        "## START YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE HERE \n",
        "\n",
        "rmse_df['RMSE-SGD-scaled'] = pd.Series(new_rmses)\n",
        "rmse_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkDgCGIIQFGX"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "What do you observe the values of RMSE? Does the scaling help? \n",
        "\n",
        "_Type your answer here_\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "    \n",
        "We can see a smaller RMSEs. Scaling has a large impact on the performance of SGD and it helps the SGD to learn better. \n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9VH-sWQFGY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}