{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/session-6/Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Welcome to the programming exercise. This is part of the series of exercises to help you acquire skills in different techniques to fine-tune your model.\n",
    "\n",
    "**You will learn:**\n",
    "- how to use SGD Regressor to train your model \n",
    "- the effects of learning rate and scaling on gradient descent-based algorithm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will load the boston housing prices. The dataset is not scaled and we train models using different regression: Linear regression, Ridge, Lasso and ElasticNet and compare the RMSE.  We then compare the RMSEs with a SGDRegressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "\n",
    "# Split the data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to calculate rmse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(ytrue, ypredicted):\n",
    "    return np.sqrt(mean_squared_error(ytrue, ypredicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a plain vanilla **Linear Regression** and calcuate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearRegression = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "linearRegression_rmse = rmse(y_test, linearRegression.predict(X_test))\n",
    "\n",
    "print(linearRegression_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train a the model using **Ridge Regression**, and find the best alpha and the best RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]\n",
    "\n",
    "ridgeCV = RidgeCV(alphas=alphas, \n",
    "                  cv=4).fit(X_train, y_train)\n",
    "\n",
    "ridgeCV_rmse = rmse(y_test, ridgeCV.predict(X_test))\n",
    "\n",
    "print(ridgeCV.alpha_, ridgeCV_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train a the model using **Lasso Regression**, and find the best alpha and the best RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alphas = np.array([1e-5, 5e-5, 0.0001, 0.0005])\n",
    "\n",
    "lassoCV = LassoCV(alphas=lasso_alphas,\n",
    "                  max_iter=5e4,\n",
    "                  cv=3).fit(X_train, y_train)\n",
    "\n",
    "lassoCV_rmse = rmse(y_test, lassoCV.predict(X_test))\n",
    "\n",
    "print(lassoCV.alpha_, lassoCV_rmse)  # Lasso is slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train a the model using **ElasticNet Regression**, and find the best alpha, l1-ratio and the best RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratios = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "elasticNetCV = ElasticNetCV(alphas=lasso_alphas, \n",
    "                            l1_ratio=l1_ratios,\n",
    "                            max_iter=1e4).fit(X_train, y_train)\n",
    "elasticNetCV_rmse = rmse(y_test, elasticNetCV.predict(X_test))\n",
    "\n",
    "print(elasticNetCV.alpha_, elasticNetCV.l1_ratio_, elasticNetCV_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will put all the best RMSEs of various models in a dataframe for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_vals = [linearRegression_rmse, ridgeCV_rmse, lassoCV_rmse, elasticNetCV_rmse]\n",
    "\n",
    "labels = ['Linear', 'Ridge', 'Lasso', 'ElasticNet']\n",
    "\n",
    "rmse_df = pd.Series(rmse_vals, index=labels).to_frame()\n",
    "rmse_df.rename(columns={0: 'RMSE'}, inplace=1)\n",
    "rmse_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use the **SGDRegressor**, and using same best hyper-parameters for ridge, lasso and elasticNet but uses the default starting learning rate (eta0) of 0.01 and the learning rate adjustment strategy of 'invscaling' i.e. eta = eta0 / pow(t, power_t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "model_parameters_dict = {\n",
    "    'Linear': {'penalty': 'none'},\n",
    "    'Lasso': {'penalty': 'l2',\n",
    "           'alpha': lassoCV.alpha_},\n",
    "    'Ridge': {'penalty': 'l1',\n",
    "           'alpha': ridgeCV.alpha_},\n",
    "    'ElasticNet': {'penalty': 'elasticnet', \n",
    "                   'alpha': elasticNetCV.alpha_ ,\n",
    "                   'l1_ratio': elasticNetCV.l1_ratio_}\n",
    "}\n",
    "\n",
    "new_rmses = {}\n",
    "for modellabel, parameters in model_parameters_dict.items():\n",
    "    # following notation passes the dict items as arguments\n",
    "    SGD = SGDRegressor(**parameters)\n",
    "    SGD.fit(X_train, y_train)\n",
    "    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test))\n",
    "\n",
    "    \n",
    "rmse_df['RMSE-SGD'] = pd.Series(new_rmses).to_frame()\n",
    "rmse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "What do you observe about the RMSE? What do you think is the reason for the observed RMSE? \n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "Notice how high the error values are! The algorithm is diverging. This can be due to scaling and/or learning rate being too high. Let's adjust the learning rate and see what happens.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Now let's try using a smaller learning rate of 1e-7 (i.e. 0.0000001) and apply the same version of SGD and compare the new RMSE of SGD with the new learning rate. \n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "for modellabel, parameters in model_parameters_dict.items():\n",
    "    # following notation passes the dict items as arguments\n",
    "    SGD = SGDRegressor(eta0=1e-7, **parameters)\n",
    "    SGD.fit(X_train, y_train)\n",
    "    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rmses = {}\n",
    "\n",
    "## START YOUR CODE HERE \n",
    "\n",
    "\n",
    "## END YOUR CODE HERE\n",
    "\n",
    "rmse_df['RMSE-SGD-learningrate'] = pd.Series(new_rmses)\n",
    "rmse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Now let's scale our training data and try again.\n",
    "\n",
    "* Fit a `MinMaxScaler` to `X_train` create a variable `X_train_scaled`.\n",
    "* Using the scaler, transform `X_test` and create a variable `X_test_scaled`. \n",
    "* Apply the same versions of SGD to them and compare the results. Don't pass in a eta0 this time.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "```python\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for modellabel, parameters in model_parameters_dict.items():\n",
    "    # following notation passes the dict items as arguments\n",
    "    SGD = SGDRegressor(**parameters)\n",
    "    SGD.fit(X_train_scaled, y_train)\n",
    "    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test_scaled))\n",
    "\n",
    "rmse_df['RMSE-SGD-scaled'] = pd.Series(new_rmses)\n",
    "rmse_df\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "new_rmses = {}\n",
    "\n",
    "## START YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE HERE \n",
    "\n",
    "rmse_df['RMSE-SGD-scaled'] = pd.Series(new_rmses)\n",
    "rmse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "What do you observe the values of RMSE? Does the scaling help? \n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "    \n",
    "We can see a smaller RMSEs. Scaling has a large impact on the performance of SGD and it helps the SGD to learn better. \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
