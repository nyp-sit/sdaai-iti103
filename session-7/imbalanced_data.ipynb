{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imbalanced_data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/session-7/imbalanced_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnqURdKXOvF9"
      },
      "source": [
        "# Dealing with Imbalanced Data Set\n",
        "\n",
        "Welcome to the hands-on lab. This is part of the series of exercises to help you acquire skills in different techniques to fine-tune your model.\n",
        "\n",
        "In this lab, you will learn:\n",
        "- how to use over-sampling correctly for imbalanced data set\n",
        "- how to perform resampling using K-folds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RwnjO0pOvF-"
      },
      "source": [
        "In this exercise, we will use an imbalanced data set from Lending Club that consists of data for both 'bad' and 'good' loans to illustrate how we can apply oversampling and undersampling techniques to improve our model performance. You will also learn to apply resampling correctly when using cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLhPfND5OvF-"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1155FtcFOvF_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    RepeatedStratifiedKFold,\n",
        "    cross_validate\n",
        ")\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    roc_auc_score,\n",
        "    auc,\n",
        "    precision_recall_curve,\n",
        "    RocCurveDisplay\n",
        ")\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from imblearn.ensemble import (\n",
        "    RUSBoostClassifier, \n",
        "    EasyEnsembleClassifier\n",
        ")\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4uzbQmnOvGE"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKm5pvtTOvGF"
      },
      "source": [
        "url = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/datasets/lending_club-data.csv.zip'\n",
        "zip_file = \"lending_club-data.csv.zip\"\n",
        "\n",
        "# download the zip file and copy to a file 'lending-club-data.csv.zip'\n",
        "with urllib.request.urlopen(url) as response, open(zip_file, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "    \n",
        "# unzip the file to a folder 'data'\n",
        "with zipfile.ZipFile(zip_file,\"r\") as zip_ref:\n",
        "    zip_ref.extractall('data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUjfEldbOvGI"
      },
      "source": [
        "## Understand the data\n",
        "\n",
        "Here we are trying to find out some information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KUTDi-oOvGJ"
      },
      "source": [
        "df = pd.read_csv('data/lending-club-data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1PMtr7wOvGP"
      },
      "source": [
        "Let us just find out about different features and their data types. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KphBoylOvGQ"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGorNXkCOvGU"
      },
      "source": [
        "In this exercise, we are trying to predict if a member will default on his loan or not. So we will be using the feature column 'bad_loans' as the label for our classification task. If the value of `bad_loan` is 1, it means it is a default (or bad loan), otherwise, it is 0.  \n",
        "\n",
        "***Exercise:***\n",
        "\n",
        "Find out how many samples in the data set is bad loans and how many are not. \n",
        "\n",
        "Hint: `value_counts()` in [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) give you the count of unique values\n",
        "\n",
        "<p>\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "df.bad_loans.value_counts()\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxAwMqOLOvGV"
      },
      "source": [
        "### Complete the code below ###\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbTZ3HYROvGZ"
      },
      "source": [
        "Is the data set imbalanced? Clearly we have a lot of more good loans than bad loans (around 4 times more)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-699YfGOvGZ"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqFZxW3POvGa"
      },
      "source": [
        "There are quite a lot of features in this data set but we are just going to use a few, just for demonstration purpose (as we are not really interested in actual performance of our model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiB1_iyKOvGb"
      },
      "source": [
        "features = ['grade', 'home_ownership','emp_length_num', 'sub_grade','short_emp',\n",
        "            'dti', 'term', 'purpose', 'int_rate', 'last_delinq_none', 'last_major_derog_none',\n",
        "            'revol_util', 'total_rec_late_fee', 'payment_inc_ratio', 'bad_loans']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcD4E6QMOvGf"
      },
      "source": [
        "df = df[features]\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54vsiwgBOvGm"
      },
      "source": [
        "Notice that `payment_inc_ratio` has some null values, and since it is only a small number, just remove the rows that have null values for `payment_inc_ratio`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2LnIJIEOvGn"
      },
      "source": [
        "loans_df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZnxh1kf-4N_"
      },
      "source": [
        "We will go ahead and encode our categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtXWlMJuOvGt"
      },
      "source": [
        "loans_encoded = pd.get_dummies(loans_df)\n",
        "loans_encoded.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pplOyf8XOvGz"
      },
      "source": [
        "### Split the data set into train and test set\n",
        "\n",
        "***Exercise:*** \n",
        "\n",
        "First, separate the features and the label.  \n",
        "\n",
        "Hint: use `df.drop()` and specify `axis=1` to remove a particular column in dataframe.\n",
        "\n",
        "Then, split the data into train set (called `X_train, y_train`) and test set (`X_test, y_test`). Think about the splitting strategy, e.g. do you need to ensure the distribution of good/bad is the same in both train and test set?\n",
        "\n",
        "<p>\n",
        "<details><summary>Click here for answer</summary>\n",
        "    \n",
        "```python\n",
        "\n",
        "X_df = loans_encoded.drop(['bad_loans'], axis=1)\n",
        "y_df = loans_encoded['bad_loans']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, \n",
        "                                                    test_size = .2, \n",
        "                                                    stratify = y_df,\n",
        "                                                    random_state = 42)\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV7UrEgrOvG0"
      },
      "source": [
        "### Complete the code below ###\n",
        "\n",
        "# X_df contains all the feature columns and y_df contains only the label, i.e. bad_loans column\n",
        "\n",
        "X_df = None\n",
        "y_df = None\n",
        "\n",
        "# split the data into train and test set\n",
        "X_train, X_test, y_train, y_test = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeEr2-jBOvG4"
      },
      "source": [
        "print(y_train.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmSMM7TE-4OA"
      },
      "source": [
        "## Train a baseline model\n",
        "\n",
        "Now for comparison sake, we will evaluate a baseline model without any resampling.\n",
        "As we are dealing with imbalanced dataset, it is useful for us to look at the roc auc score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VK2hJam-4OB"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('ROC_AUC of baseline model = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1EwpPy2-4OB"
      },
      "source": [
        "## Oversampling\n",
        "\n",
        "Now we will try the over-sampling techniques to see if we can improve our model performance on the 'bad loan'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms9xSxclOvG-"
      },
      "source": [
        "### The ***wrong*** way to oversample ###\n",
        "\n",
        "With the training data created, we can oversample the minority class (the bad_loan = 1). In this exercise, we will use the SMOTE (from the [imblearn](https://imbalanced-learn.readthedocs.io/en/stable/index.html) library) to create synthetic samples of the minority class. \n",
        "\n",
        "After upsampling to a class ratio of 1.0 (i.e. 1 to 1 ratio between positive and negative classes) you should have a balanced dataset. In most cases, there’s often no need to balance the classes totally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09afPcnaOvG_"
      },
      "source": [
        "# Set sampling_strategy='auto' to oversample only the minority class \n",
        "\n",
        "sm = SMOTE(sampling_strategy='auto',random_state=0)\n",
        "\n",
        "X_upsample, y_upsample = sm.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYewJVUYOvHB"
      },
      "source": [
        "Now let's see the number of samples we have for each class. You will see that now our train set is totally balanced, with equal number of samples for each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzcmiL-YOvHC"
      },
      "source": [
        "y_upsample.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ewnQ5JOvHI"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_upsample, y_upsample, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Cross-validation ROC_AUC score SMOTE-wrong way = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdknGvRgOvHV"
      },
      "source": [
        "Our roc_auc score has improved to 93%. Impressive!  But is this actually representative of how the model will perform? Let's put our model to test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyl14DBIOvHL"
      },
      "source": [
        "Now let's train the model using the full up-sampled training set and evaluate on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5LXxQ5IOvHM"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "clf.fit(X_upsample, y_upsample)\n",
        "\n",
        "y_probas = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_probas)\n",
        "\n",
        "print('Test ROC_AUC with SMOTE-wrong way = {}'.format(roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INAtz44QOvHa"
      },
      "source": [
        "You will get around 0.68. That’s disappointing! What has happened?\n",
        "\n",
        "By oversampling before splitting into training and validation datasets, we “leaked” information from the validation set into the training of the model (refer to your lecture for more details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-fkAmtpOvHb"
      },
      "source": [
        "### The ***right way*** to oversample\n",
        "\n",
        "So, let do it the right way and see what happens. This time round, we will oversample the training set and not the train + validation set. Oversampling is done after we set aside the validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfPMduTK-4OD"
      },
      "source": [
        "sm = SMOTE(sampling_strategy='auto', random_state=0)\n",
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "\n",
        "# declare a pipeline that consists of the oversampler and the classifier\n",
        "steps = [('ovr', sm), ('clf', clf)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# the oversampling is only applied to the train folds\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(pipeline, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('average roc_auc = {}'.format(scores['test_roc_auc'].mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXzlMLEl-4OD"
      },
      "source": [
        "## Undersampling\n",
        "\n",
        "It does not seems that we have much success with oversampling (it is marginally better than the baseline model). Let us try undersampling to see if we can get a better model.\n",
        "\n",
        "**Exercise:**\n",
        "\n",
        "Complete the code cell below, using RandomUndersampler, resample only the majority class. Cross-validate with RandomForestClassifier like before and compare the result with the oversampling approach. What do you observe about the result?\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```python\n",
        "\n",
        "undersampler  = RandomUnderSampler(sampling_strategy='auto', random_state=0)\n",
        "clf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "\n",
        "# declare a pipeline that consists of the oversampler and the classifier\n",
        "steps = [('under', undersampler), ('clf', clf)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# the oversampling is only applied to the train folds\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "scores = cross_validate(pipeline, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Cross-validation ROC_AUC score Random Undersampling = {}'.format(scores['test_roc_auc'].mean()))\n",
        "    \n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvTaBr3H-4OD"
      },
      "source": [
        "## Complete the code below ##\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FqZZfCD-4OE"
      },
      "source": [
        "## Boosting\n",
        "\n",
        "Let us try some boosting algorithm to see if we can achieve better result. \n",
        "\n",
        "**Exercise:**\n",
        "\n",
        "Complete the code cell below, using GradientBoostingClassifier, with default parameters and random_state=0\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```python\n",
        "clf = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
        "scores = cross_validate(clf, X_train, y_train, scoring=['roc_auc'], cv=cv, n_jobs=-1)\n",
        "print('Cross-validate ROC_AUC with GradientBoosting = {}'.format(scores['test_roc_auc'].mean()))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar83qC13-4OE"
      },
      "source": [
        "### Complete code below ###\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItHRXKgP-4OE"
      },
      "source": [
        "Here we can see that even without any re-sampling, boosting algorithm is able to achieve better result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k12HQ0b8-4OE"
      },
      "source": [
        "### Complete the code below ### \n",
        "clf = RUSBoostClassifier(n_estimators=30, sampling_strategy='auto', learning_rate=1.0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}